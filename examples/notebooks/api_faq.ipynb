{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQ for MXFusion APIs\n",
    "\n",
    "**Zhenwen Dai (2019-05-30)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How to access a variable or a factor in my model?\n",
    "\n",
    "There are a few ways to access a variable or a factor in a model:\n",
    "\n",
    "1. If a variable is named such as ```m.x = Variable()```, we use ```x``` as the name of the variable and this variable can be accessed later by calling ```m.x```.\n",
    "2. A factor can also be named in the way as a variable, e.g., ```m.f = MXFusionGluonFunction(func, 1)```, in which we name the wrapper of a MXNet function ```func``` as ```f```. This function can be accessed by calling ```m.f```.\n",
    "3. If a variable is the random variable following a distribution or the output of a function, e.g., ```m.x = Normal.define_variable(mx.nd.array([0]), mx.nd.array([1]), shape=(1,))```, the distribution or the function can be accessed by calling ```m.x.factor```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How does a ```Posterior``` instance link to my model?\n",
    "\n",
    "When stochastic variational inference, we often need to specify the variational posterior by hand. This can be done by creating a ```Posterior``` instance from our model definition ```m```, e.g., ```q = Posterior(m)```. After the creation of the ```Posterior``` instance, all the variables defined in the model also exist in the posterior under the same names. For example, if a variable ```m.x``` is defined in the model, the same variable can be access via ```q.x``` in the posterior. A variational posterior is often constructed by defining the posterior distributions for all the latent variables. For example, we can specify a variational posterior for the variable ```x``` by ```q.x.assign_factor(Normal(mx.nd.array([0]), mx.nd.array([1])))```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How to access the parameters after inference?\n",
    "\n",
    "The inference in MXFusion is done by creating an ```Inference``` object, which takes an inference algorithm as the input argument. After the execution of the inference algorithm, all estimated parameters are stored in a ```InferenceParameters``` object. If we have an ```Inference``` instance ```infr```, the ```InferenceParameters``` can be access by ```infr.params```. The individual parameters in the model and posterior can be obtained by passing in the reference of the corresponding variables, e.g., ```infr.params[m.x]``` returns the estimated value of the parameter ```x``` in the model ```m```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How to serialize the inference results?\n",
    "\n",
    "Serialization can be conveniently in MXFusion by simply calling the ```save``` method of a ```Inference``` instance, which takes a filename as the input argument. An example is shown below:\n",
    "```python\n",
    "m = Model()\n",
    "...\n",
    "infr = ...\n",
    "infr.save('inference_file.zip')\n",
    "```\n",
    "\n",
    "To load back the inference result of a model, one need recreate the model and posterior instance and the corresponding inference instance with exactly the same configurations. Then, the estimated parameters can be loaded by calling the ```load``` method of the ```Inference``` instance. See the example below:\n",
    "```python\n",
    "m = Model()\n",
    "...\n",
    "infr = ...\n",
    "infr.load('inference_file.zip')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. How to run the computation in single/double (float32/float64) precision?\n",
    "\n",
    "When creating random variables from probabilistic distributions and the ```Inference``` instance, the argument ```dtype``` specifies the precision of the corresponding objects. At the moment, we only support the single and double precision by taking the value \"float32\" or \"float64\".\n",
    "\n",
    "Alternatively, the computation precision can be set globally by changing the default precision type:\n",
    "```python\n",
    "from mxfusion.common import config\n",
    "config.DEFAULT_DTYPE = 'float64'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. How to run the computation on GPU?\n",
    "\n",
    "When creating random variables from probabilistic distributions and the ```Inference``` instance, the argument ```ctx``` or ```context``` specifies the device in which the variables are expected to be stored. One can pass in the MXNet device reference such as ```mxnet.gpu()``` to switch the computation to be run on GPU.\n",
    "\n",
    "Alternatively, the computational device can also be set globally by changing the default device of MXNet:\n",
    "```python\n",
    "import mxnet as mx\n",
    "mx.context.Context.device_ctx = mx.gpu()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. How to view TensorBoard logs?\n",
    "\n",
    "To use TensorBoard to inspect inference logs you must have TensorBoard and MXBoard installed. Instructions for installing these packages can be found [here](https://github.com/awslabs/mxboard).\n",
    "\n",
    "To produce the logs required for TensorBoard, pass a ```Logger``` with a ```log_dir``` (and an optional ```log_name```) to your inference object instantiation.\n",
    "\n",
    "```python\n",
    "infr = Inference(logger=Logger(log_dir='logs'))\n",
    "```\n",
    "\n",
    "To run the TensorBoard server to view the results, run the following command (for more details see [here](https://www.tensorflow.org/guide/summaries_and_tensorboard)):\n",
    "```\n",
    "$ tensorboard --logdir=path/to/log-directory\n",
    "```\n",
    "\n",
    "Now you can open the server in a browser and view the logs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
